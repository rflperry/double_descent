{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a77f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys; sys.path.append('../../PGDL/sample_code_submission/')\n",
    "from internal_rep.matrix_funcs import \\\n",
    "    get_KF_Schatten_norms, \\\n",
    "    compute_complexity, \\\n",
    "    get_df_tau, \\\n",
    "    evalues_from_regions, \\\n",
    "    get_local_rad_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27854d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(x, y, n_samples, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        np.random.seed(int(time.time()))\n",
    "\n",
    "    indices = np.random.choice(range(x.shape[0]), size=n_samples, replace=False)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    return x, y\n",
    "\n",
    "def prepare_mnist_dataset(\n",
    "    batch_size=64,\n",
    "    train_sample_size=None,\n",
    "    test_sample_size=None,\n",
    "    seed=None,\n",
    "    shuffle=True,\n",
    "    shuffle_label_frac=None\n",
    "):\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()#path='/mnt/ssd3/ronan/tensorflow_datasets/')\n",
    "    y_train = y_train.astype('int32')\n",
    "    y_test = y_test.astype('int32')\n",
    "\n",
    "    if train_sample_size is not None:\n",
    "        x_train, y_train = sample_dataset(x_train, y_train, int(train_sample_size), seed)\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.arange(train_sample_size)\n",
    "            np.random.seed(seed)\n",
    "            np.random.shuffle(shuffle_indices)\n",
    "            x_train = x_train[shuffle_indices]\n",
    "            y_train = y_train[shuffle_indices]\n",
    "        if shuffle_label_frac is not None:\n",
    "            n_shuffle = int(shuffle_label_frac * train_sample_size)\n",
    "            y_shuffle = y_train[:n_shuffle]\n",
    "            np.random.seed(seed)\n",
    "            np.random.shuffle(y_shuffle)\n",
    "            y_train[:n_shuffle] = y_shuffle\n",
    "\n",
    "    if test_sample_size is not None:\n",
    "        x_test, y_test = sample_dataset(x_test, y_test, int(test_sample_size), seed)\n",
    "\n",
    "    x_train, x_test = tf.cast(x_train, tf.float32) / 255.0, tf.cast(x_test, tf.float32) / 255.0\n",
    "    print(f\"x_train.shape={x_train.shape} y_train={y_train.shape} \"\n",
    "                 f\"x_test.shape={x_test.shape} y_test={y_test.shape}\")\n",
    "\n",
    "    shuffle_buffer = 1000\n",
    "    prefetch_buffer = 1000\n",
    "    dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    # dataset = dataset.shuffle(shuffle_buffer)\n",
    "    dataset_train = dataset_train.prefetch(prefetch_buffer).batch(batch_size)\n",
    "    dataset_test = dataset_test.prefetch(prefetch_buffer).batch(batch_size)\n",
    "    \n",
    "    return dataset_train, dataset_test # , (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405fe8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, n_epochs, optimizer, loss_fn, metric, metric_dict={}, save_path=None, epoch_save=5):\n",
    "    @tf.function\n",
    "    def _train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            loss_value = loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric\n",
    "        metric.update_state(y, logits)\n",
    "        return loss_value\n",
    "\n",
    "    # @tf.function\n",
    "    def _test_step(x, y):\n",
    "        logits = model(x, training=False)\n",
    "        # Update val metrics\n",
    "        metric.update_state(y, logits)\n",
    "        return logits, y\n",
    "\n",
    "    model_results = defaultdict(list)\n",
    "    model_results['epochs'] = n_epochs\n",
    "    \n",
    "    train_eval_mat = []\n",
    "    test_eval_mat = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        losses = []\n",
    "        for step, (x_batch, y_batch) in enumerate(ds_train):\n",
    "            loss_value = _train_step(x_batch, y_batch)\n",
    "            losses.append(loss_value)\n",
    "        model_results['train_loss'].append(np.mean(losses))\n",
    "            \n",
    "        # Display metrics at the end of each epoch.\n",
    "        train_acc = metric.result()\n",
    "        metric.reset_states()\n",
    "        \n",
    "        model_results['train_accuracy'].append(train_acc)\n",
    "        \n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        logit_list = []\n",
    "        y_list = []\n",
    "        for x_batch, y_batch in ds_test:\n",
    "            logits, y = _test_step(x_batch, y_batch)\n",
    "            logit_list.append(logits)\n",
    "            y_list.append(y)\n",
    "        y_list = tf.concat(y_list, axis=0)\n",
    "        logit_list = tf.concat(logit_list, axis=0)\n",
    "        model_results['test_ece'].append(tfp.stats.expected_calibration_error(10, logit_list, y_list))\n",
    "        \n",
    "            \n",
    "        test_acc = metric.result()\n",
    "        metric.reset_states()\n",
    "        model_results['test_accuracy'].append(test_acc)\n",
    "        \n",
    "        # Get the TRAIN complexity at the end of each epoch\n",
    "        for label, ds in zip(('train', 'test'), (ds_train, ds_test)):\n",
    "            internal_rep = []\n",
    "            for x_batch, y_batch in ds:\n",
    "                for layer in model.layers[:-1]:\n",
    "                    x_batch = layer(x_batch)\n",
    "                internal_rep.append((x_batch.numpy() > 0).astype('bool'))\n",
    "            internal_rep = np.vstack(internal_rep)\n",
    "            evalues = evalues_from_regions(internal_rep)\n",
    "            if epoch % epoch_save == 0:\n",
    "                if label == 'train':\n",
    "                    train_eval_mat.append(evalues)\n",
    "                elif label == 'test':\n",
    "                    test_eval_mat.append(evalues)\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "                \n",
    "            h_star, h_argmin = get_local_rad_bound(evalues, from_evalues=True)\n",
    "            model_results[f'h*_{label}'].append(h_star)\n",
    "            model_results[f'h_argmin_{label}'].append(h_argmin)\n",
    "            model_results[f'n_activated_regions_{label}'].append(sum(evalues > 0))\n",
    "        \n",
    "        # Get the TEST complexity at the end of each epoch\n",
    "\n",
    "        \n",
    "        if epoch % epoch_save == 0:\n",
    "            print(f\"Epoch {epoch}: Training acc={train_acc:.3f}, Validation acc={test_acc:.3f}\")\n",
    "        \n",
    "    if save_path is not None:\n",
    "        np.save(save_path + '_train_evalues.npy', train_eval_mat)\n",
    "        np.save(save_path + '_test_evalues.npy', test_eval_mat)\n",
    "        with open(save_path + '_results_dict.pkl', 'wb') as f:\n",
    "            pickle.dump(model_results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return model, model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b0187",
   "metadata": {},
   "source": [
    "## Run and save models, varying width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b710c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.123, Validation acc=0.149\n",
      "Epoch 5: Training acc=0.449, Validation acc=0.439\n",
      "Epoch 10: Training acc=0.581, Validation acc=0.532\n",
      "Epoch 15: Training acc=0.635, Validation acc=0.580\n",
      "Epoch 20: Training acc=0.692, Validation acc=0.617\n",
      "Epoch 25: Training acc=0.715, Validation acc=0.632\n",
      "Epoch 30: Training acc=0.752, Validation acc=0.663\n",
      "Epoch 35: Training acc=0.782, Validation acc=0.692\n",
      "Epoch 40: Training acc=0.798, Validation acc=0.705\n",
      "Epoch 45: Training acc=0.811, Validation acc=0.712\n",
      "Epoch 50: Training acc=0.823, Validation acc=0.717\n",
      "Epoch 55: Training acc=0.830, Validation acc=0.722\n",
      "Epoch 60: Training acc=0.850, Validation acc=0.728\n",
      "Epoch 65: Training acc=0.860, Validation acc=0.730\n",
      "Epoch 70: Training acc=0.864, Validation acc=0.734\n",
      "Epoch 75: Training acc=0.875, Validation acc=0.737\n",
      "Epoch 80: Training acc=0.880, Validation acc=0.738\n",
      "Epoch 85: Training acc=0.885, Validation acc=0.741\n",
      "Epoch 90: Training acc=0.891, Validation acc=0.745\n",
      "Epoch 95: Training acc=0.898, Validation acc=0.747\n",
      "Epoch 100: Training acc=0.904, Validation acc=0.748\n",
      "Epoch 105: Training acc=0.907, Validation acc=0.749\n",
      "Epoch 110: Training acc=0.909, Validation acc=0.751\n",
      "Epoch 115: Training acc=0.914, Validation acc=0.753\n",
      "Epoch 120: Training acc=0.919, Validation acc=0.751\n",
      "Epoch 125: Training acc=0.925, Validation acc=0.751\n",
      "Epoch 130: Training acc=0.934, Validation acc=0.752\n",
      "Epoch 135: Training acc=0.939, Validation acc=0.753\n",
      "Epoch 140: Training acc=0.942, Validation acc=0.755\n",
      "Epoch 145: Training acc=0.947, Validation acc=0.755\n",
      "Epoch 150: Training acc=0.949, Validation acc=0.756\n",
      "Epoch 155: Training acc=0.953, Validation acc=0.757\n",
      "Epoch 160: Training acc=0.956, Validation acc=0.757\n",
      "Epoch 165: Training acc=0.958, Validation acc=0.758\n",
      "Epoch 170: Training acc=0.960, Validation acc=0.759\n",
      "Epoch 175: Training acc=0.960, Validation acc=0.760\n",
      "Epoch 180: Training acc=0.961, Validation acc=0.761\n",
      "Epoch 185: Training acc=0.962, Validation acc=0.762\n",
      "Epoch 190: Training acc=0.962, Validation acc=0.761\n",
      "Epoch 195: Training acc=0.967, Validation acc=0.762\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.197, Validation acc=0.272\n",
      "Epoch 5: Training acc=0.708, Validation acc=0.695\n",
      "Epoch 10: Training acc=0.824, Validation acc=0.776\n",
      "Epoch 15: Training acc=0.877, Validation acc=0.807\n",
      "Epoch 20: Training acc=0.904, Validation acc=0.825\n",
      "Epoch 25: Training acc=0.923, Validation acc=0.835\n",
      "Epoch 30: Training acc=0.938, Validation acc=0.842\n",
      "Epoch 35: Training acc=0.950, Validation acc=0.846\n",
      "Epoch 40: Training acc=0.960, Validation acc=0.849\n",
      "Epoch 45: Training acc=0.962, Validation acc=0.851\n",
      "Epoch 50: Training acc=0.968, Validation acc=0.851\n",
      "Epoch 55: Training acc=0.973, Validation acc=0.853\n",
      "Epoch 60: Training acc=0.976, Validation acc=0.854\n",
      "Epoch 65: Training acc=0.983, Validation acc=0.853\n",
      "Epoch 70: Training acc=0.985, Validation acc=0.854\n",
      "Epoch 75: Training acc=0.989, Validation acc=0.854\n",
      "Epoch 80: Training acc=0.991, Validation acc=0.854\n",
      "Epoch 85: Training acc=0.994, Validation acc=0.855\n",
      "Epoch 90: Training acc=0.996, Validation acc=0.855\n",
      "Epoch 95: Training acc=0.997, Validation acc=0.855\n",
      "Epoch 100: Training acc=0.999, Validation acc=0.855\n",
      "Epoch 105: Training acc=0.999, Validation acc=0.855\n",
      "Epoch 110: Training acc=0.999, Validation acc=0.856\n",
      "Epoch 115: Training acc=0.999, Validation acc=0.857\n",
      "Epoch 120: Training acc=0.999, Validation acc=0.856\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.856\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.855\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.855\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.203, Validation acc=0.306\n",
      "Epoch 5: Training acc=0.852, Validation acc=0.806\n",
      "Epoch 10: Training acc=0.915, Validation acc=0.852\n",
      "Epoch 15: Training acc=0.942, Validation acc=0.870\n",
      "Epoch 20: Training acc=0.964, Validation acc=0.878\n",
      "Epoch 25: Training acc=0.973, Validation acc=0.883\n",
      "Epoch 30: Training acc=0.982, Validation acc=0.885\n",
      "Epoch 35: Training acc=0.985, Validation acc=0.885\n",
      "Epoch 40: Training acc=0.991, Validation acc=0.886\n",
      "Epoch 45: Training acc=0.997, Validation acc=0.885\n",
      "Epoch 50: Training acc=0.998, Validation acc=0.885\n",
      "Epoch 55: Training acc=0.999, Validation acc=0.884\n",
      "Epoch 60: Training acc=0.999, Validation acc=0.885\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.883\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.883\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.882\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.882\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.881\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.880\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.879\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.879\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.879\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.879\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.377, Validation acc=0.558\n",
      "Epoch 5: Training acc=0.892, Validation acc=0.857\n",
      "Epoch 10: Training acc=0.938, Validation acc=0.877\n",
      "Epoch 15: Training acc=0.961, Validation acc=0.883\n",
      "Epoch 20: Training acc=0.976, Validation acc=0.887\n",
      "Epoch 25: Training acc=0.990, Validation acc=0.887\n",
      "Epoch 30: Training acc=0.996, Validation acc=0.888\n",
      "Epoch 35: Training acc=0.996, Validation acc=0.889\n",
      "Epoch 40: Training acc=0.999, Validation acc=0.888\n",
      "Epoch 45: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 50: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 55: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 60: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.887\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.343, Validation acc=0.542\n",
      "Epoch 5: Training acc=0.908, Validation acc=0.863\n",
      "Epoch 10: Training acc=0.951, Validation acc=0.882\n",
      "Epoch 15: Training acc=0.978, Validation acc=0.888\n",
      "Epoch 20: Training acc=0.991, Validation acc=0.890\n",
      "Epoch 25: Training acc=0.997, Validation acc=0.890\n",
      "Epoch 30: Training acc=0.999, Validation acc=0.890\n",
      "Epoch 35: Training acc=0.999, Validation acc=0.891\n",
      "Epoch 40: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 45: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 50: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 55: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 60: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.890\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.436, Validation acc=0.621\n",
      "Epoch 5: Training acc=0.923, Validation acc=0.870\n",
      "Epoch 10: Training acc=0.963, Validation acc=0.883\n",
      "Epoch 15: Training acc=0.985, Validation acc=0.887\n",
      "Epoch 20: Training acc=0.995, Validation acc=0.888\n",
      "Epoch 25: Training acc=0.999, Validation acc=0.889\n",
      "Epoch 30: Training acc=0.999, Validation acc=0.890\n",
      "Epoch 35: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 40: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 45: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 50: Training acc=1.000, Validation acc=0.891\n",
      "Epoch 55: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 60: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.890\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.889\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.887\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.888\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.888\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.449, Validation acc=0.682\n",
      "Epoch 5: Training acc=0.932, Validation acc=0.874\n",
      "Epoch 10: Training acc=0.967, Validation acc=0.888\n",
      "Epoch 15: Training acc=0.992, Validation acc=0.891\n",
      "Epoch 20: Training acc=0.999, Validation acc=0.893\n",
      "Epoch 25: Training acc=0.999, Validation acc=0.893\n",
      "Epoch 30: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 35: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 40: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 45: Training acc=1.000, Validation acc=0.893\n",
      "Epoch 50: Training acc=1.000, Validation acc=0.893\n",
      "Epoch 55: Training acc=1.000, Validation acc=0.893\n",
      "Epoch 60: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.894\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 130: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.895\n",
      "x_train.shape=(1000, 28, 28) y_train=(1000,) x_test.shape=(10000, 28, 28) y_test=(10000,)\n",
      "Epoch 0: Training acc=0.471, Validation acc=0.709\n",
      "Epoch 5: Training acc=0.940, Validation acc=0.883\n",
      "Epoch 10: Training acc=0.977, Validation acc=0.891\n",
      "Epoch 15: Training acc=0.994, Validation acc=0.893\n",
      "Epoch 20: Training acc=0.999, Validation acc=0.893\n",
      "Epoch 25: Training acc=0.999, Validation acc=0.895\n",
      "Epoch 30: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 35: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 40: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 45: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 50: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 55: Training acc=1.000, Validation acc=0.895\n",
      "Epoch 60: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 65: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 70: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 75: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 80: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 85: Training acc=1.000, Validation acc=0.896\n",
      "Epoch 90: Training acc=1.000, Validation acc=0.897\n",
      "Epoch 95: Training acc=1.000, Validation acc=0.897\n",
      "Epoch 100: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 105: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 110: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 115: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 120: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 125: Training acc=1.000, Validation acc=0.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 135: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 140: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 145: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 150: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 155: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 160: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 165: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 170: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 175: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 180: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 185: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 190: Training acc=1.000, Validation acc=0.898\n",
      "Epoch 195: Training acc=1.000, Validation acc=0.898\n"
     ]
    }
   ],
   "source": [
    "n_train_sample = 1000\n",
    "n_units_list = [4, 8, 16, 32, 48, 64, 80, 100]\n",
    "n_epochs = 200\n",
    "\n",
    "for n_units in n_units_list:\n",
    "    total_params = (28 * 28 + 1) * n_units + (n_units + 1) * 10\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),#input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(n_units, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    # model = tf.keras.models.clone_model(model_base)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    ds_train, ds_test = prepare_mnist_dataset(\n",
    "        train_sample_size=n_train_sample, test_sample_size=10000,\n",
    "        seed=0)\n",
    "    \n",
    "    model, model_results = fit_model(\n",
    "        model, n_epochs, optimizer, loss_fn, metric,\n",
    "        save_path=f'./width_results/relu_net_units={n_units}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fbb0f7",
   "metadata": {},
   "source": [
    "## Run and save models, varying depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_sample = 1000\n",
    "n_units_list = [4, 8, 16, 32, 48, 64, 80, 100]\n",
    "n_epochs = 200\n",
    "\n",
    "for n_units in n_units_list:\n",
    "    total_params = (28 * 28 + 1) * n_units + (n_units + 1) * 10\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),#input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(n_units, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    # model = tf.keras.models.clone_model(model_base)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    \n",
    "    ds_train, ds_test = prepare_mnist_dataset(\n",
    "        train_sample_size=n_train_sample, test_sample_size=10000,\n",
    "        seed=0)\n",
    "    \n",
    "    model, model_results = fit_model(\n",
    "        model, n_epochs, optimizer, loss_fn, metric,\n",
    "        save_path=f'./depth_results/relu_net_units={n_units}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proglearn)",
   "language": "python",
   "name": "proglearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
