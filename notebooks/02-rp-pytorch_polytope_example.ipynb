{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch example of polytope complexity\n",
    "Notes:\n",
    "- As a complexity measure, this may be used to measure complexity during training for early stopping reasons, or after training.\n",
    "- For large samples sizes and networks, the current implementation may be slow.\n",
    "- The number of polytopes may be highly sensitive to initialization, stopping criterion, or other randomness. So it is recommended to average across these and compute variances.\n",
    "- In over-trained networks or very complex networks, it is often observed that each sample will lie in it's own polytope (saturation of the network). This may be due to either an overfit model or the prevelance of neighboring polytopes with similar linear functions in them due to ReLUs that don't meaningfully impact the network (imagine an outgoing weight of 0).\n",
    "- One may also care about the distribution of samples in polytopes. That has been studied but is more complex of a subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "X_train, y_train = make_moons(100)\n",
    "my_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train).long()) # create your datset\n",
    "train_loader = DataLoader(my_dataset, batch_size=batch_size) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "hidden_size = 5\n",
    "num_classes = 2\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Fully connected neural network with two hidden layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size) ,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polytope functions\n",
    "def get_polytopes(model, dataloader, penultimate=False):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    From a ReLU neural network and a training dataset, computes the number of polytopes\n",
    "    occupied by the training samples relative to the sample size. Each polytope\n",
    "    corresponds to a fixed assignment of all ReLU's as either on/off and within each\n",
    "    polytope the network is a linear function. One may think of this fraction\n",
    "    as the relative number of piecewise linear functions a network has to learn on the\n",
    "    data in order to perform well.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : pytorch sequential network with ReLUs\n",
    "    dataloader : training data loader\n",
    "    penultimate : boolean, default False\n",
    "        If True, only returns polytopes using the last layer of ReLUs. Set to True\n",
    "        if all the prior layers are viewed as a representation learner.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fraction : float\n",
    "        Fraction of training samples in unique polytopes.\n",
    "    polytope_assignments : list, length=dataloader_sample_size\n",
    "        Labels encoding which samples occured in which polytopes.\n",
    "    \"\"\"\n",
    "    all_memberships = []\n",
    "    n_samples = 0\n",
    "    \n",
    "    for train_x, _ in dataloader:\n",
    "        n_samples += train_x.shape[0]\n",
    "        polytope_memberships = []\n",
    "        for layer in model: # Assumes sequential, may have to adjust based on model\n",
    "            train_x = layer(train_x)\n",
    "            if type(layer) == nn.ReLU:\n",
    "                binary_preactivation = (train_x.detach().numpy() > 0).astype('int')\n",
    "                polytope_memberships.append(binary_preactivation)\n",
    "    \n",
    "        if penultimate:\n",
    "            polytope_memberships = polytope_memberships[-1]\n",
    "        else:\n",
    "            polytope_memberships = np.hstack(polytope_memberships)\n",
    "        all_memberships.append(polytope_memberships)\n",
    "    \n",
    "    polytopes, assignments = np.unique(np.vstack(all_memberships), axis=0, return_inverse=True)\n",
    "    \n",
    "    return len(polytopes) / n_samples, assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly, labels = get_polytopes(model, train_loader, penultimate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n",
      "[ 4  6  9  0  0  0  0  6  0  9  8  2  1  8  0  0  4  1  5  0  0  6  0  5\n",
      "  6  0  6  9  0  0  8  8 10  9  6  9  5  0  0  5  5  1  3  4  0  7  7  0\n",
      "  0  0  7  0  0  0  7  2  5  0  9  4  3  7  9  2  0  2  8  2  8  7  4  7\n",
      "  8  2  9  0  9  4  4  9  0  9 11  0  4  4  0  0  8  6  4  1  0  9  4  0\n",
      "  6  0  4  7]\n"
     ]
    }
   ],
   "source": [
    "print(poly)\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
